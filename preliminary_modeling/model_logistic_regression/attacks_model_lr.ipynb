{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91d0a57c-3245-47e2-b509-5ba929b42321",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956fdda4-5aff-42f0-bd31-322519341e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "attacks = pd.read_csv('../data/attack_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbaaffae-5c0b-4d91-a13b-82734dba976d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>This is not creative  Those are the dictionar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less NPOV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>True or false the situation as of March 2002...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next maybe you could work on being less conde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  target\n",
       "0   37675   This is not creative  Those are the dictionar...       0\n",
       "1   44816     the term standard model is itself less NPOV...       0\n",
       "2   49851    True or false the situation as of March 2002...       0\n",
       "3   89320   Next maybe you could work on being less conde...       0\n",
       "4   93890                This page will need disambiguation        0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7d695b1-d5a8-4952-8c44-ef557f537b9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.865338\n",
       "1    0.134662\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attacks['target'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b050d236-2866-405b-bd88-a8323835b988",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, pct_positive, test_size=None, train_size=None,\n",
    "random_state=None):\n",
    "    \"\"\"\n",
    "    A custom train_test_split implementation that creates a training dataset\n",
    "    with a specific proportion of positive classes. This is meant to\n",
    "    combat class imbalance in training data ONLY. Testing data will retain the\n",
    "    original class proportions.\n",
    "    Args:\n",
    "        data -- the dataframe acquired from merge_with_target()\n",
    "        pct_positive -- desired proportion of positive classes in training data.\n",
    "            (float between 0 and 1)\n",
    "        test_size -- number of samples to include in the testing dataset.\n",
    "            (integer, default None --> 20% of the full dataset)\n",
    "        train_size -- number of samples to include in the training dataset.\n",
    "            (integer, default None --> maximum training size for given\n",
    "            parameters)\n",
    "    \"\"\"\n",
    "    # get test data\n",
    "    if test_size:\n",
    "        num_test_samples = int(test_size)\n",
    "    else:\n",
    "        num_test_samples = int(0.3 * data.shape[0])\n",
    "\n",
    "    df_test = data.sample(num_test_samples, random_state=random_state)\n",
    "    X_test = df_test['comment']\n",
    "    y_test = df_test['target']\n",
    "\n",
    "    # get train data\n",
    "    # separate positive and negative classes\n",
    "    df_train = data.drop(df_test.index)\n",
    "    df_train_pos = df_train[df_train['target'] == 1]\n",
    "    df_train_neg = df_train[df_train['target'] == 0]\n",
    "\n",
    "    # some input validation for train_size\n",
    "    max_train_size = int(df_train_pos.shape[0] / pct_positive)\n",
    "    if not train_size:\n",
    "        train_size = max_train_size\n",
    "    elif train_size > max_train_size:\n",
    "        warnings.warn(f'train_size of {train_size} exceeds the amount of '\n",
    "        'training data available for the given parameters. '\n",
    "        f'Resetting train size to {max_train_size}')\n",
    "        train_size = max_train_size\n",
    "    else:\n",
    "        train_size = int(train_size)\n",
    "\n",
    "    # assemble train dataframe\n",
    "    num_pos_samples = int(pct_positive * train_size)\n",
    "    num_neg_samples = train_size - num_pos_samples\n",
    "\n",
    "    df_train = pd.concat([\n",
    "        df_train_pos.sample(num_pos_samples, random_state=random_state),\n",
    "        df_train_neg.sample(num_neg_samples)]).sample(\n",
    "        frac=1, random_state=random_state)\n",
    "\n",
    "    X_train = df_train['comment']\n",
    "    y_train = df_train['target']\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cab1185e-5c4d-4ec7-a6b8-f821fc39d716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom train/test split using function Christian created to create equal classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(data = attacks, pct_positive = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4669a388-55bf-4983-8557-99eb418023c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store model results\n",
    "\n",
    "column_names = ['model', 'file', 'cv__stop_words', 'cv__max_df', 'cv__max_features', 'cv__min_df', 'cv__ngram_range', 'training_score', 'test_score']\n",
    "\n",
    "model_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Create function to add results to model df\n",
    "\n",
    "def add_to_model(df, model, name, file):\n",
    "    df = df.append({'model'           : name,\n",
    "                    'file'            : file,\n",
    "                    'cv__stop_words'  : model.best_params_['cv__stop_words'],\n",
    "                    'cv__max_df'      : model.best_params_['cv__max_df'],\n",
    "                    'cv__max_features': model.best_params_['cv__max_features'],\n",
    "                    'cv__min_df'      : model.best_params_['cv__min_df'],\n",
    "                    'cv__ngram_range' : model.best_params_['cv__ngram_range'],\n",
    "                    'training_score'  : model.score(X_train, y_train),\n",
    "                    'test_score'      : model.score(X_test, y_test)},\n",
    "                    ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07ca0b38-a960-4c6c-8d01-28d89690ea64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to count vectorize and run logistic regression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8232c14e-baa7-4e90-b3e3-b89281cd766a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters for pipeline\n",
    "\n",
    "pipe_params = {\n",
    "    'cv__stop_words'  : [None, 'english'],\n",
    "    'cv__max_features': [11_000, 12_000, 13_000],\n",
    "    'cv__min_df'      : [2, 3],\n",
    "    'cv__max_df'      : [.80, .85],\n",
    "    'cv__ngram_range' : [(1, 1), (2, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "273ca513-1dc5-45a3-beee-ddcbf2005425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate gridsearch\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator  = pipe,\n",
    "    param_grid = pipe_params,\n",
    "    cv = 5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "163da0b0-9f1e-4610-b2a2-b72a68f5a25d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             param_grid={'cv__max_df': [0.8, 0.85],\n",
       "                         'cv__max_features': [11000, 12000, 13000],\n",
       "                         'cv__min_df': [2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cv__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the gridsearch\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "39fde7bb-741c-4ddb-b21c-1084591bbef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = add_to_model(model_df, gs, 'logistic regression', 'attacks')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d180d2c8-c24a-4e52-af5f-372112263b7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>file</th>\n",
       "      <th>cv__stop_words</th>\n",
       "      <th>cv__max_df</th>\n",
       "      <th>cv__max_features</th>\n",
       "      <th>cv__min_df</th>\n",
       "      <th>cv__ngram_range</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>attacks</td>\n",
       "      <td>None</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.956063</td>\n",
       "      <td>0.883812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>attacks</td>\n",
       "      <td>None</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.960635</td>\n",
       "      <td>0.884822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>attacks</td>\n",
       "      <td>None</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.960635</td>\n",
       "      <td>0.884822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model     file cv__stop_words  cv__max_df cv__max_features  \\\n",
       "0  logistic regression  attacks           None        0.90            10000   \n",
       "1  logistic regression  attacks           None        0.85            12000   \n",
       "2  logistic regression  attacks           None        0.80            12000   \n",
       "\n",
       "  cv__min_df cv__ngram_range  training_score  test_score  \n",
       "0          2          (1, 1)        0.956063    0.883812  \n",
       "1          2          (1, 1)        0.960635    0.884822  \n",
       "2          2          (1, 1)        0.960635    0.884822  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f765616-192e-4cb0-82c1-86e4a470f7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('../data/lr_model_results.csv', index = False, mode = 'a', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c75fca9-73a6-49d2-8eea-a621d58ad187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
