{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cf76c01d-5a69-458e-8f86-6d7f0b707b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03ed71b0-a26b-4007-8fbf-444895a4f334",
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic = pd.read_csv('../data/toxicity_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8154508d-c536-4ff7-b68f-d4c95d89dc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232</td>\n",
       "      <td>This  One can make an analogy in mathematical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216</td>\n",
       "      <td>Clarification for you  (and Zundark's right, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547</td>\n",
       "      <td>This is such a fun entry.   DevotchkaI once ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  toxicity\n",
       "0    2232  This  One can make an analogy in mathematical ...         0\n",
       "1    4216  Clarification for you  (and Zundark's right, i...         0\n",
       "2    8953                          Elected or Electoral? JHK         0\n",
       "3   26547  This is such a fun entry.   DevotchkaI once ha...         0\n",
       "4   28959  Please relate the ozone hole to increases in c...         0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fc241605-6201-49d9-b4bf-83b083b2eef9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.884373\n",
       "1    0.115627\n",
       "Name: toxicity, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic['toxicity'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "605d8a97-de93-4d45-baaa-4579afdbe1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, pct_positive, test_size=None, train_size=None,\n",
    "random_state=None):\n",
    "    \"\"\"\n",
    "    A custom train_test_split implementation that creates a training dataset\n",
    "    with a specific proportion of positive classes. This is meant to\n",
    "    combat class imbalance in training data ONLY. Testing data will retain the\n",
    "    original class proportions.\n",
    "    Args:\n",
    "        data -- the dataframe acquired from merge_with_target()\n",
    "        pct_positive -- desired proportion of positive classes in training data.\n",
    "            (float between 0 and 1)\n",
    "        test_size -- number of samples to include in the testing dataset.\n",
    "            (integer, default None --> 20% of the full dataset)\n",
    "        train_size -- number of samples to include in the training dataset.\n",
    "            (integer, default None --> maximum training size for given\n",
    "            parameters)\n",
    "    \"\"\"\n",
    "    # get test data\n",
    "    if test_size:\n",
    "        num_test_samples = int(test_size)\n",
    "    else:\n",
    "        num_test_samples = int(0.3 * data.shape[0])\n",
    "\n",
    "    df_test = data.sample(num_test_samples, random_state=random_state)\n",
    "    X_test = df_test['comment']\n",
    "    y_test = df_test['toxicity']\n",
    "\n",
    "    # get train data\n",
    "    # separate positive and negative classes\n",
    "    df_train = data.drop(df_test.index)\n",
    "    df_train_pos = df_train[df_train['toxicity'] == 1]\n",
    "    df_train_neg = df_train[df_train['toxicity'] == 0]\n",
    "\n",
    "    # some input validation for train_size\n",
    "    max_train_size = int(df_train_pos.shape[0] / pct_positive)\n",
    "    if not train_size:\n",
    "        train_size = max_train_size\n",
    "    elif train_size > max_train_size:\n",
    "        warnings.warn(f'train_size of {train_size} exceeds the amount of '\n",
    "        'training data available for the given parameters. '\n",
    "        f'Resetting train size to {max_train_size}')\n",
    "        train_size = max_train_size\n",
    "    else:\n",
    "        train_size = int(train_size)\n",
    "\n",
    "    # assemble train dataframe\n",
    "    num_pos_samples = int(pct_positive * train_size)\n",
    "    num_neg_samples = train_size - num_pos_samples\n",
    "\n",
    "    df_train = pd.concat([\n",
    "        df_train_pos.sample(num_pos_samples, random_state=random_state),\n",
    "        df_train_neg.sample(num_neg_samples)]).sample(\n",
    "        frac=1, random_state=random_state)\n",
    "\n",
    "    X_train = df_train['comment']\n",
    "    y_train = df_train['toxicity']\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5539b6a7-7285-49e4-bf96-d22d9b245e59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom train/test split using function Christian created to create equal classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(data = toxic, pct_positive = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d3bcee4b-255a-4477-9df9-64630e323546",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store model results\n",
    "\n",
    "column_names = ['model', 'file', 'cv__stop_words', 'cv__max_df', 'cv__max_features', 'cv__min_df', 'cv__ngram_range', 'training_score', 'test_score']\n",
    "\n",
    "model_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Create function to add results to model df\n",
    "\n",
    "def add_to_model(df, model, name, file):\n",
    "    df = df.append({'model'           : name,\n",
    "                    'file'            : file,\n",
    "                    'cv__stop_words'  : model.best_params_['cv__stop_words'],\n",
    "                    'cv__max_df'      : model.best_params_['cv__max_df'],\n",
    "                    'cv__max_features': model.best_params_['cv__max_features'],\n",
    "                    'cv__min_df'      : model.best_params_['cv__min_df'],\n",
    "                    'cv__ngram_range' : model.best_params_['cv__ngram_range'],\n",
    "                    'training_score'  : model.score(X_train, y_train),\n",
    "                    'test_score'      : model.score(X_test, y_test)},\n",
    "                    ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9532c96-0dc2-4f14-b3a2-d81923505439",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to count vectorize and run logistic regression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter=1000))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00b4ba12-0c69-4056-a5b2-baeeb89878f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters for pipeline\n",
    "\n",
    "pipe_params = {\n",
    "    'cv__stop_words'  : [None, 'english'],\n",
    "    'cv__max_features': [11_000, 12_000, 13_000],\n",
    "    'cv__min_df'      : [2, 3],\n",
    "    'cv__max_df'      : [.85, .9],\n",
    "    'cv__ngram_range' : [(1, 1), (2, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa4ae4aa-2866-4896-8516-2f8598d12775",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate gridsearch\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator  = pipe,\n",
    "    param_grid = pipe_params,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fda473d9-1b19-4590-9fa9-2bd5b9321376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             param_grid={'cv__max_df': [0.85, 0.9],\n",
       "                         'cv__max_features': [11000, 12000, 13000],\n",
       "                         'cv__min_df': [2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cv__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the gridsearch\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f842ec7f-7781-4e97-a1c3-68f058d86bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = add_to_model(model_df, gs, 'logistic regression', 'toxic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a2719b37-4f05-4786-b482-4983337ba85f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>file</th>\n",
       "      <th>cv__stop_words</th>\n",
       "      <th>cv__max_df</th>\n",
       "      <th>cv__max_features</th>\n",
       "      <th>cv__min_df</th>\n",
       "      <th>cv__ngram_range</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>None</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>None</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>None</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model   file cv__stop_words  cv__max_df cv__max_features  \\\n",
       "0  logistic regression  toxic           None        0.90            12000   \n",
       "1  logistic regression  toxic           None        0.85            12000   \n",
       "2  logistic regression  toxic           None        0.85            12000   \n",
       "\n",
       "  cv__min_df cv__ngram_range  training_score  test_score  \n",
       "0          3          (1, 1)        0.965972    0.896686  \n",
       "1          3          (1, 1)        0.965972    0.896686  \n",
       "2          3          (1, 1)        0.965972    0.896686  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "787ec784-36c2-47d0-baa3-20cd9eff122a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('../data/lr_model_results.csv', index = False, mode = 'a', header = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3449a7a-9a0c-4b4c-8d95-40a4b25a125f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
