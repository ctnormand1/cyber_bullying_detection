{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29446fb",
   "metadata": {},
   "source": [
    "# Model Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aca5b7",
   "metadata": {},
   "source": [
    "In Cyberbulling text detection, we should optimize for sensitivity (recall). We want to maximize the number of true positives predicted and decrease the number of false negatives. This will decrease the risk of cyberbulling comment without going undetected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b18536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../eda_cleaning/')\n",
    "from eda_functions import split_data\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6ea2f",
   "metadata": {},
   "source": [
    "## Aggression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c14bbbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>aggression</th>\n",
       "      <th>aggression_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>This is not creative  Those are the dictionary...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less NPOV t...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>True or false the situation as of March 2002 w...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next maybe you could work on being less conde...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year  logged_in  \\\n",
       "0   37675  This is not creative  Those are the dictionary...  2002       True   \n",
       "1   44816   the term standard model is itself less NPOV t...  2002       True   \n",
       "2   49851  True or false the situation as of March 2002 w...  2002       True   \n",
       "3   89320   Next maybe you could work on being less conde...  2002       True   \n",
       "4   93890                This page will need disambiguation   2002       True   \n",
       "\n",
       "        ns  sample  split  aggression  aggression_score  label  \n",
       "0  article  random  train    0.100000          0.000000      0  \n",
       "1  article  random  train    0.000000          0.111111      0  \n",
       "2  article  random  train    0.000000          0.100000      0  \n",
       "3  article  random    dev    0.444444         -0.444444      0  \n",
       "4  article  random  train    0.000000          0.333333      0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in cleaned aggression file\n",
    "aggression_df = pd.read_csv('../clean data/aggression_clean_data.csv')\n",
    "aggression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96d2adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and rename label column\n",
    "aggression_df = aggression_df[['rev_id','comment','label']]\n",
    "aggression_df.rename(columns={'label':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "609b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom train test split function to balance the classes in the training data only\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3b4d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train (n=23824)</th>\n",
       "      <th>Test (n=34647)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.853147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.146853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train (n=23824)  Test (n=34647)\n",
       "0              0.5        0.853147\n",
       "1              0.5        0.146853"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the split for the train and test data\n",
    "pd.DataFrame({\n",
    "    f'Train (n={y_train.shape[0]})': y_train.value_counts(normalize=True),\n",
    "    f'Test (n={y_test.shape[0]})': y_test.value_counts(normalize=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a209372",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "61ae3311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with best parameters found from XGBoost gridsearch\n",
    "cvec = CountVectorizer(max_df = 0.95,\n",
    "                    max_features = 5000,\n",
    "                    min_df = 3,\n",
    "                    ngram_range = (1, 1),\n",
    "                    stop_words = 'english',\n",
    "                    strip_accents = 'ascii',\n",
    "                    token_pattern = '\\\\w+|[A-Z]\\\\w+')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec_xg = cvec.transform(X_train)\n",
    "X_test_cvec_xg = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43c7ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBoost with best parameters found from gridsearch\n",
    "xg = XGBClassifier(colsample_bytree = 0.75, n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "469585f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:17:26] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "xg.fit(X_train_cvec_xg, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f0266bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696540880503144"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, xg.predict(X_test_cvec_xg))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946803b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3a219267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Naive Bayes gridsearch\n",
    "cvec = CountVectorizer(ngram_range = (1, 1),\n",
    "                    stop_words = None)\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec_mnb = cvec.transform(X_train)\n",
    "X_test_cvec_mnb = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb13511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Naive Bayes\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ed66b4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "mnb.fit(X_train_cvec_mnb, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "64e2b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7696540880503144"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, mnb.predict(X_test_cvec_mnb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88077fe",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "472bb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Logistic Regression gridsearch\n",
    "cvec = CountVectorizer(stop_words = None,\n",
    "                       max_df = 0.95,\n",
    "                       max_features = 15000,\n",
    "                       min_df = 3,\n",
    "                       ngram_range = (1, 1))\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec_lr = cvec.transform(X_train)\n",
    "X_test_cvec_lr = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae2390f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Logistic Regression\n",
    "lr = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e345f7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lr.fit(X_train_cvec_lr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb1afbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294025157232704"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, lr.predict(X_test_cvec_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44583d8",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f07e8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from SVC gridsearch\n",
    "cvec = CountVectorizer(max_features = 4000,\n",
    "                       ngram_range = (1, 1),\n",
    "                       stop_words = 'english')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec_svc = cvec.transform(X_train)\n",
    "X_test_cvec_svc = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd4a83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SVC\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f7f38208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "svc.fit(X_train_cvec_svc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "810768d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6035770440251572"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, svc.predict(X_test_cvec_svc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a649a1e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
