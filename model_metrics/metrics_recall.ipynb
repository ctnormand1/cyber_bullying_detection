{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c29446fb",
   "metadata": {},
   "source": [
    "# Model Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9aca5b7",
   "metadata": {},
   "source": [
    "In Cyberbulling text detection, we should optimize for sensitivity (recall). We want to maximize the number of true positives predicted and decrease the number of false negatives. This will decrease the risk of cyberbulling comment without going undetected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7b18536",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "sys.path.append('../eda_cleaning/')\n",
    "from eda_functions import split_data\n",
    "\n",
    "from sklearn.metrics import recall_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37728abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to store recall scores in a DataFrame\n",
    "recall_df = pd.DataFrame(columns = ['topic', 'model', 'recall_score'])\n",
    "\n",
    "def add_scores(topic, name, model):\n",
    "    df = pd.DataFrame(columns = ['topic', 'model', 'recall_score'])\n",
    "    df = df.append({'topic': topic,\n",
    "                    'model': name,\n",
    "                    'recall_score': recall_score(y_test, model.predict(X_test_cvec))},\n",
    "                    ignore_index=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad6ea2f",
   "metadata": {},
   "source": [
    "## Aggression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14bbbee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>aggression</th>\n",
       "      <th>aggression_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>This is not creative  Those are the dictionary...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less NPOV t...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>True or false the situation as of March 2002 w...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next maybe you could work on being less conde...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year  logged_in  \\\n",
       "0   37675  This is not creative  Those are the dictionary...  2002       True   \n",
       "1   44816   the term standard model is itself less NPOV t...  2002       True   \n",
       "2   49851  True or false the situation as of March 2002 w...  2002       True   \n",
       "3   89320   Next maybe you could work on being less conde...  2002       True   \n",
       "4   93890                This page will need disambiguation   2002       True   \n",
       "\n",
       "        ns  sample  split  aggression  aggression_score  label  \n",
       "0  article  random  train    0.100000          0.000000      0  \n",
       "1  article  random  train    0.000000          0.111111      0  \n",
       "2  article  random  train    0.000000          0.100000      0  \n",
       "3  article  random    dev    0.444444         -0.444444      0  \n",
       "4  article  random  train    0.000000          0.333333      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in cleaned aggression file\n",
    "aggression_df = pd.read_csv('../clean data/aggression_clean_data.csv')\n",
    "aggression_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "96d2adab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and rename label column\n",
    "aggression_df = aggression_df[['rev_id','comment','label']]\n",
    "aggression_df.rename(columns={'label':'target'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "609b4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom train test split function to balance the classes in the training data only\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3b4d5a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train (n=23824)</th>\n",
       "      <th>Test (n=34647)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.853147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.146853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train (n=23824)  Test (n=34647)\n",
       "0              0.5        0.853147\n",
       "1              0.5        0.146853"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the split for the train and test data\n",
    "pd.DataFrame({\n",
    "    f'Train (n={y_train.shape[0]})': y_train.value_counts(normalize=True),\n",
    "    f'Test (n={y_test.shape[0]})': y_test.value_counts(normalize=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a209372",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61ae3311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with best parameters found from XGBoost gridsearch\n",
    "cvec = CountVectorizer(max_df = 0.95,\n",
    "                    max_features = 5000,\n",
    "                    min_df = 3,\n",
    "                    ngram_range = (1, 1),\n",
    "                    stop_words = 'english',\n",
    "                    strip_accents = 'ascii',\n",
    "                    token_pattern = '\\\\w+|[A-Z]\\\\w+')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c7ad6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBoost with best parameters found from gridsearch\n",
    "xg = XGBClassifier(colsample_bytree = 0.75, n_estimators = 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "469585f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:37:02] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.75, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=200, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "xg.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f0266bf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7682783018867925"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, xg.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cdc458ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('aggression', 'XGBoost', xg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "de1a627d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>model</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aggression</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        topic    model  recall_score\n",
       "0  aggression  XGBoost      0.768278"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_scores('aggression', 'XGBoost', xg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946803b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a219267",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Naive Bayes gridsearch\n",
    "cvec = CountVectorizer(ngram_range = (1, 1),\n",
    "                    stop_words = None)\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fb13511c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Naive Bayes\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed66b4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "mnb.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "64e2b3f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7635613207547169"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, mnb.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f6ec725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('aggression', 'Naive Bayes', mnb), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88077fe",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "472bb7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Logistic Regression gridsearch\n",
    "cvec = CountVectorizer(stop_words = None,\n",
    "                       max_df = 0.95,\n",
    "                       max_features = 15000,\n",
    "                       min_df = 3,\n",
    "                       ngram_range = (1, 1))\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ae2390f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Logistic Regression\n",
    "lr = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e345f7bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lr.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eb1afbc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8294025157232704"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, lr.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b5fa83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('aggression', 'Logistic Regression', lr), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c44583d8",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f07e8015",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    aggression_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from SVC gridsearch\n",
    "cvec = CountVectorizer(max_features = 4000,\n",
    "                       ngram_range = (1, 1),\n",
    "                       stop_words = 'english')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd4a83b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SVC\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7f38208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "svc.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "810768d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6191037735849056"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, svc.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "993daa50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('aggression', 'SVC', svc), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e626da91",
   "metadata": {},
   "source": [
    "## Toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7e3271aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232</td>\n",
       "      <td>This  One can make an analogy in mathematical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216</td>\n",
       "      <td>Clarification for you  (and Zundark's right, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547</td>\n",
       "      <td>This is such a fun entry.   DevotchkaI once ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  toxicity\n",
       "0    2232  This  One can make an analogy in mathematical ...         0\n",
       "1    4216  Clarification for you  (and Zundark's right, i...         0\n",
       "2    8953                          Elected or Electoral? JHK         0\n",
       "3   26547  This is such a fun entry.   DevotchkaI once ha...         0\n",
       "4   28959  Please relate the ozone hole to increases in c...         0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in cleaned toxicity file\n",
    "toxicity_df = pd.read_csv('../clean data/toxicity_cleaned.csv')\n",
    "toxicity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d8948ba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232</td>\n",
       "      <td>This  One can make an analogy in mathematical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216</td>\n",
       "      <td>Clarification for you  (and Zundark's right, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547</td>\n",
       "      <td>This is such a fun entry.   DevotchkaI once ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  target\n",
       "0    2232  This  One can make an analogy in mathematical ...       0\n",
       "1    4216  Clarification for you  (and Zundark's right, i...       0\n",
       "2    8953                          Elected or Electoral? JHK       0\n",
       "3   26547  This is such a fun entry.   DevotchkaI once ha...       0\n",
       "4   28959  Please relate the ozone hole to increases in c...       0"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaname toxicity column\n",
    "toxicity_df.rename(columns={'toxicity': 'target'}, inplace=True)\n",
    "toxicity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ec638889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom train test split function to balance the classes in the training data only\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    toxicity_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8d38c696",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train (n=25624)</th>\n",
       "      <th>Test (n=47680)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.883284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.116716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train (n=25624)  Test (n=47680)\n",
       "0              0.5        0.883284\n",
       "1              0.5        0.116716"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the split for the train and test data\n",
    "pd.DataFrame({\n",
    "    f'Train (n={y_train.shape[0]})': y_train.value_counts(normalize=True),\n",
    "    f'Test (n={y_test.shape[0]})': y_test.value_counts(normalize=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74798031",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "914dfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with best parameters found from XGBoost gridsearch\n",
    "cvec = CountVectorizer(max_df = 0.95,\n",
    "                    max_features = 5000,\n",
    "                    min_df = 2,\n",
    "                    ngram_range = (1, 1),\n",
    "                    stop_words = 'english',\n",
    "                    strip_accents = 'ascii',\n",
    "                    token_pattern = '\\\\w+|[A-Z]\\\\w+')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f3961f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBoost with best parameters found from gridsearch\n",
    "xg = XGBClassifier(colsample_bytree = 0.7, n_estimators = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a2a34d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:40:16] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.7, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "xg.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b14176a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7960467205750225"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, xg.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "acbead32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('toxicity', 'XGBoost', xg), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953d139b",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0d4d69b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    toxicity_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Naive Bayes gridsearch\n",
    "cvec = CountVectorizer(ngram_range = (1, 1),\n",
    "                    stop_words = None)\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "99c1b458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Naive Bayes\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1ad200cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "mnb.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "eaa9e16c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8361185983827494"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, mnb.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3660c8cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('toxicity', 'Naive Bayes', mnb), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c468b1a",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "58197e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    toxicity_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Logistic Regression gridsearch\n",
    "cvec = CountVectorizer(stop_words = None,\n",
    "                       max_df = 0.85,\n",
    "                       max_features = 13000,\n",
    "                       min_df = 2,\n",
    "                       ngram_range = (1, 1))\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e47f2f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Logistic Regression\n",
    "lr = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "23e02710",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lr.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6e21e22b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8612758310871519"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, lr.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "4a439221",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = recall_df.append(add_scores('toxicity', 'Logistic Regression', lr), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20907253",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6051890d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    toxicity_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from SVC gridsearch\n",
    "cvec = CountVectorizer(max_features = 4000,\n",
    "                       ngram_range = (1, 1),\n",
    "                       stop_words = 'english')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a9885a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SVC\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "93a200e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "svc.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6446cfac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7773584905660378"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, svc.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "25798992",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = recall_df.append(add_scores('toxicity', 'SVC', svc), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "758580ec",
   "metadata": {},
   "source": [
    "## Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47e48cb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>This is not creative  Those are the dictionar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less NPOV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>True or false the situation as of March 2002...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next maybe you could work on being less conde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  target\n",
       "0   37675   This is not creative  Those are the dictionar...       0\n",
       "1   44816     the term standard model is itself less NPOV...       0\n",
       "2   49851    True or false the situation as of March 2002...       0\n",
       "3   89320   Next maybe you could work on being less conde...       0\n",
       "4   93890                This page will need disambiguation        0"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in cleaned attack file\n",
    "attack_df = pd.read_csv('../clean data/attack_clean.csv')\n",
    "attack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "057f1617",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom train test split function to balance the classes in the training data only\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    attack_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c23d9455",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Train (n=21872)</th>\n",
       "      <th>Test (n=34668)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.866563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.133437</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Train (n=21872)  Test (n=34668)\n",
       "0              0.5        0.866563\n",
       "1              0.5        0.133437"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View the split for the train and test data\n",
    "pd.DataFrame({\n",
    "    f'Train (n={y_train.shape[0]})': y_train.value_counts(normalize=True),\n",
    "    f'Test (n={y_test.shape[0]})': y_test.value_counts(normalize=True)})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd8324d",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "620215f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate CountVectorizer with best parameters found from XGBoost gridsearch\n",
    "cvec = CountVectorizer(max_df = 0.95,\n",
    "                    max_features = 6000,\n",
    "                    min_df = 3,\n",
    "                    ngram_range = (1, 1),\n",
    "                    stop_words = 'english',\n",
    "                    strip_accents = 'ascii',\n",
    "                    token_pattern = '\\\\w+|[A-Z]\\\\w+')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "661795a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate XGBoost with best parameters found from gridsearch\n",
    "xg = XGBClassifier(colsample_bytree = 0.6, n_estimators = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "f215add2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:43:59] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=0.6, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=250, n_jobs=8, num_parallel_tree=1, random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "xg.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7de72ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7853437094682231"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, xg.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cbc4e2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = recall_df.append(add_scores('attack', 'XGBoost', xg), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd538e40",
   "metadata": {},
   "source": [
    "### Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1d6c20c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    attack_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Naive Bayes gridsearch\n",
    "cvec = CountVectorizer(ngram_range = (1, 1),\n",
    "                    stop_words = None)\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00fd3907",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Naive Bayes\n",
    "mnb = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9a9d7b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "mnb.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a5a12da1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7788586251621271"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, mnb.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1f86179",
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_df = recall_df.append(add_scores('attack', 'Naive Bayes', mnb), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02836c4",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "892f4a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    attack_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from Logistic Regression gridsearch\n",
    "cvec = CountVectorizer(stop_words = None,\n",
    "                       max_df = 0.8,\n",
    "                       max_features = 12000,\n",
    "                       min_df = 2,\n",
    "                       ngram_range = (1, 1))\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc3b702a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate Logistic Regression\n",
    "lr = LogisticRegressionCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8a94a46e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegressionCV()"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "lr.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "c9e8522a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389537397319499"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, lr.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4c7ab5c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('attack', 'Logistic Regression', lr), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ce7cac1",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5f13fd57",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    attack_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)\n",
    "\n",
    "# Instantiate CountVectorizer with best parameters found from SVC gridsearch\n",
    "cvec = CountVectorizer(max_features = 6000,\n",
    "                       min_df = 2,\n",
    "                       stop_words = 'english')\n",
    "cvec.fit(X_train)\n",
    "\n",
    "X_train_cvec = cvec.transform(X_train)\n",
    "X_test_cvec = cvec.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cc65f0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate SVC\n",
    "svc = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "df35543d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC()"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "svc.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0cdb2ed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6394293125810635"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recall score\n",
    "recall_score(y_test, svc.predict(X_test_cvec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "aa8c199c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add score\n",
    "recall_df = recall_df.append(add_scores('attack', 'SVC', svc), ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c730c9",
   "metadata": {},
   "source": [
    "## View All Recall Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "3f7a6d27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topic</th>\n",
       "      <th>model</th>\n",
       "      <th>recall_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aggression</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.768278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aggression</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.763561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aggression</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.829403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggression</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.619104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>toxicity</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.796047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>toxicity</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.836119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>toxicity</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.861276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>toxicity</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.777358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>attack</td>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.785344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>attack</td>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.778859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>attack</td>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.838954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>attack</td>\n",
       "      <td>SVC</td>\n",
       "      <td>0.639429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         topic                model  recall_score\n",
       "0   aggression              XGBoost      0.768278\n",
       "1   aggression          Naive Bayes      0.763561\n",
       "2   aggression  Logistic Regression      0.829403\n",
       "3   aggression                  SVC      0.619104\n",
       "4     toxicity              XGBoost      0.796047\n",
       "5     toxicity          Naive Bayes      0.836119\n",
       "6     toxicity  Logistic Regression      0.861276\n",
       "7     toxicity                  SVC      0.777358\n",
       "8       attack              XGBoost      0.785344\n",
       "9       attack          Naive Bayes      0.778859\n",
       "10      attack  Logistic Regression      0.838954\n",
       "11      attack                  SVC      0.639429"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
