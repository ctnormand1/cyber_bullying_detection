{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbe2230-0463-4fbe-aa9b-e7443dfef102",
   "metadata": {},
   "source": [
    "## Model XGBoost - Toxic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "496eb591-4c4f-41d9-8809-e17c6b484599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from eda_functions import split_data\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2c2db717-ef1c-46e3-b7e6-ae68cf753ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>toxicity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232</td>\n",
       "      <td>This  One can make an analogy in mathematical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216</td>\n",
       "      <td>Clarification for you  (and Zundark's right, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547</td>\n",
       "      <td>This is such a fun entry.   DevotchkaI once ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  toxicity\n",
       "0    2232  This  One can make an analogy in mathematical ...         0\n",
       "1    4216  Clarification for you  (and Zundark's right, i...         0\n",
       "2    8953                          Elected or Electoral? JHK         0\n",
       "3   26547  This is such a fun entry.   DevotchkaI once ha...         0\n",
       "4   28959  Please relate the ozone hole to increases in c...         0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in cleaned toxicity file\n",
    "toxicity_df = pd.read_csv('../data/toxicity_cleaned.csv')\n",
    "toxicity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7755074-5bc3-4d94-92aa-693e50d5016c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2232</td>\n",
       "      <td>This  One can make an analogy in mathematical ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4216</td>\n",
       "      <td>Clarification for you  (and Zundark's right, i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8953</td>\n",
       "      <td>Elected or Electoral? JHK</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>26547</td>\n",
       "      <td>This is such a fun entry.   DevotchkaI once ha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28959</td>\n",
       "      <td>Please relate the ozone hole to increases in c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  target\n",
       "0    2232  This  One can make an analogy in mathematical ...       0\n",
       "1    4216  Clarification for you  (and Zundark's right, i...       0\n",
       "2    8953                          Elected or Electoral? JHK       0\n",
       "3   26547  This is such a fun entry.   DevotchkaI once ha...       0\n",
       "4   28959  Please relate the ozone hole to increases in c...       0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaname toxicity column\n",
    "toxicity_df.rename(columns={'toxicity': 'target'}, inplace=True)\n",
    "toxicity_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "8c2b35e0-00f1-477a-9870-25874d292f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom train test split function to balance the classes in the training data only\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    toxicity_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1aac9e72-870f-488c-93b3-7ef9baf7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with CountVectorizer and XGBClassifier\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f2ebbb6d-91ce-44f9-ae5d-363d8cfdfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df'      : [2],\n",
    "    'cvec__max_df'      : [.95],\n",
    "    'cvec__stop_words'  : ['english'],\n",
    "    'cvec__token_pattern' : [r'\\w+|[A-Z]\\w+'],\n",
    "    'cvec__strip_accents' : ['ascii'],\n",
    "    'cvec__ngram_range' : [(1,1)],\n",
    "    'xgb__colsample_bytree': [0.7],\n",
    "    'xgb__n_estimators': [250]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5e677d2b-d553-491b-994d-48005856f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate Gridsearch\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                     param_grid = pipe_params,\n",
    "                     cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f7a1f43-09ed-47f1-8fff-e6dbb73ad220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:55:25] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:29] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:33] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[11:55:45] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan...\n",
       "                                                      tree_method=None,\n",
       "                                                      use_label_encoder=False,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'cvec__max_df': [0.95], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [2], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'cvec__strip_accents': ['ascii'],\n",
       "                         'cvec__token_pattern': ['\\\\w+|[A-Z]\\\\w+'],\n",
       "                         'xgb__colsample_bytree': [0.7],\n",
       "                         'xgb__n_estimators': [250]})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e2f349d0-eb7c-4d16-b2e0-c06153fc1ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9166016234779893\n",
      "Test score: 0.9177642617449664\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "eb418d05-baaf-45d7-bc65-09ae2ff621f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model_for_app/xgboost_toxic.pkl', 'wb') as pickle_out:\n",
    "    pickle_out = pickle.dump(gs, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704b4b7-2ec4-4321-97ea-cef63739e58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
