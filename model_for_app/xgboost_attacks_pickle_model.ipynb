{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebbe2230-0463-4fbe-aa9b-e7443dfef102",
   "metadata": {},
   "source": [
    "## Model XGBoost - Attacks Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "496eb591-4c4f-41d9-8809-e17c6b484599",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from eda_functions import split_data\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c2db717-ef1c-46e3-b7e6-ae68cf753ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>This is not creative  Those are the dictionar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less NPOV...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>True or false the situation as of March 2002...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next maybe you could work on being less conde...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  target\n",
       "0   37675   This is not creative  Those are the dictionar...       0\n",
       "1   44816     the term standard model is itself less NPOV...       0\n",
       "2   49851    True or false the situation as of March 2002...       0\n",
       "3   89320   Next maybe you could work on being less conde...       0\n",
       "4   93890                This page will need disambiguation        0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in cleaned attack file\n",
    "attack_df = pd.read_csv('../data/attack_clean.csv')\n",
    "attack_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c2b35e0-00f1-477a-9870-25874d292f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the custom train test split function to balance the classes in the training data only\n",
    "X_train, X_test, y_train, y_test = split_data(\n",
    "    attack_df,\n",
    "    pct_positive=0.5,\n",
    "    random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1aac9e72-870f-488c-93b3-7ef9baf7e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a pipeline with CountVectorizer and XGBClassifier\n",
    "pipe = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('xgb', XGBClassifier(use_label_encoder=False))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2ebbb6d-91ce-44f9-ae5d-363d8cfdfa72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "pipe_params = {\n",
    "    'cvec__max_features': [6_000],\n",
    "    'cvec__min_df'      : [3],\n",
    "    'cvec__max_df'      : [.95],\n",
    "    'cvec__stop_words'  : ['english'],\n",
    "    'cvec__token_pattern' : [r'\\w+|[A-Z]\\w+'],\n",
    "    'cvec__strip_accents' : ['ascii'],\n",
    "    'cvec__ngram_range' : [(1,1)],\n",
    "    'xgb__colsample_bytree': [0.6],\n",
    "    'xgb__n_estimators': [250]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e677d2b-d553-491b-994d-48005856f9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instatiate Gridsearch\n",
    "gs = GridSearchCV(estimator = pipe,\n",
    "                     param_grid = pipe_params,\n",
    "                     cv = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f7a1f43-09ed-47f1-8fff-e6dbb73ad220",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:47:27] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:47:32] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:47:37] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:47:41] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:47:45] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:47:50] WARNING: /opt/concourse/worker/volumes/live/7a2b9f41-3287-451b-6691-43e9a6c0910f/volume/xgboost-split_1619728204606/work/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('xgb',\n",
       "                                        XGBClassifier(base_score=None,\n",
       "                                                      booster=None,\n",
       "                                                      colsample_bylevel=None,\n",
       "                                                      colsample_bynode=None,\n",
       "                                                      colsample_bytree=None,\n",
       "                                                      gamma=None, gpu_id=None,\n",
       "                                                      importance_type='gain',\n",
       "                                                      interaction_constraints=None,\n",
       "                                                      learning_rate=None,\n",
       "                                                      max_delta_step=None,\n",
       "                                                      max_depth=None,\n",
       "                                                      min_child_weight=None,\n",
       "                                                      missing=nan...\n",
       "                                                      tree_method=None,\n",
       "                                                      use_label_encoder=False,\n",
       "                                                      validate_parameters=None,\n",
       "                                                      verbosity=None))]),\n",
       "             param_grid={'cvec__max_df': [0.95], 'cvec__max_features': [6000],\n",
       "                         'cvec__min_df': [3], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'cvec__stop_words': ['english'],\n",
       "                         'cvec__strip_accents': ['ascii'],\n",
       "                         'cvec__token_pattern': ['\\\\w+|[A-Z]\\\\w+'],\n",
       "                         'xgb__colsample_bytree': [0.6],\n",
       "                         'xgb__n_estimators': [250]})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2f349d0-eb7c-4d16-b2e0-c06153fc1ba4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9047640819312363\n",
      "Test score: 0.9091092650282682\n"
     ]
    }
   ],
   "source": [
    "print(f'Train score: {gs.score(X_train, y_train)}')\n",
    "print(f'Test score: {gs.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "eb418d05-baaf-45d7-bc65-09ae2ff621f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../model_for_app/xgboost_attacks.pkl', 'wb') as pickle_out:\n",
    "    pickle_out = pickle.dump(gs, pickle_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704b4b7-2ec4-4321-97ea-cef63739e58e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
