{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c2d711c-94c0-47ae-aeba-87508d332feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3bf40d26-4422-43cb-aef9-a4db845f238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "aggression = pd.read_csv('../data/aggression_clean_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d28af39-65ab-464f-a71c-d65f984d2e45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rev_id</th>\n",
       "      <th>comment</th>\n",
       "      <th>year</th>\n",
       "      <th>logged_in</th>\n",
       "      <th>ns</th>\n",
       "      <th>sample</th>\n",
       "      <th>split</th>\n",
       "      <th>aggression</th>\n",
       "      <th>aggression_score</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37675</td>\n",
       "      <td>This is not creative  Those are the dictionary...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44816</td>\n",
       "      <td>the term standard model is itself less NPOV t...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>49851</td>\n",
       "      <td>True or false the situation as of March 2002 w...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89320</td>\n",
       "      <td>Next maybe you could work on being less conde...</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>dev</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>-0.444444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>93890</td>\n",
       "      <td>This page will need disambiguation</td>\n",
       "      <td>2002</td>\n",
       "      <td>True</td>\n",
       "      <td>article</td>\n",
       "      <td>random</td>\n",
       "      <td>train</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rev_id                                            comment  year  logged_in  \\\n",
       "0   37675  This is not creative  Those are the dictionary...  2002       True   \n",
       "1   44816   the term standard model is itself less NPOV t...  2002       True   \n",
       "2   49851  True or false the situation as of March 2002 w...  2002       True   \n",
       "3   89320   Next maybe you could work on being less conde...  2002       True   \n",
       "4   93890                This page will need disambiguation   2002       True   \n",
       "\n",
       "        ns  sample  split  aggression  aggression_score  label  \n",
       "0  article  random  train    0.100000          0.000000      0  \n",
       "1  article  random  train    0.000000          0.111111      0  \n",
       "2  article  random  train    0.000000          0.100000      0  \n",
       "3  article  random    dev    0.444444         -0.444444      0  \n",
       "4  article  random  train    0.000000          0.333333      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccba646c-9552-4084-88bd-796d8136bb1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.852805\n",
       "1    0.147195\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggression['label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "624292d4-249c-40e3-a25c-4e72d73e542b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data, pct_positive, test_size=None, train_size=None,\n",
    "random_state=None):\n",
    "    \"\"\"\n",
    "    A custom train_test_split implementation that creates a training dataset\n",
    "    with a specific proportion of positive classes. This is meant to\n",
    "    combat class imbalance in training data ONLY. Testing data will retain the\n",
    "    original class proportions.\n",
    "    Args:\n",
    "        data -- the dataframe acquired from merge_with_target()\n",
    "        pct_positive -- desired proportion of positive classes in training data.\n",
    "            (float between 0 and 1)\n",
    "        test_size -- number of samples to include in the testing dataset.\n",
    "            (integer, default None --> 20% of the full dataset)\n",
    "        train_size -- number of samples to include in the training dataset.\n",
    "            (integer, default None --> maximum training size for given\n",
    "            parameters)\n",
    "    \"\"\"\n",
    "    # get test data\n",
    "    if test_size:\n",
    "        num_test_samples = int(test_size)\n",
    "    else:\n",
    "        num_test_samples = int(0.3 * data.shape[0])\n",
    "\n",
    "    df_test = data.sample(num_test_samples, random_state=random_state)\n",
    "    X_test = df_test['comment']\n",
    "    y_test = df_test['label']\n",
    "\n",
    "    # get train data\n",
    "    # separate positive and negative classes\n",
    "    df_train = data.drop(df_test.index)\n",
    "    df_train_pos = df_train[df_train['label'] == 1]\n",
    "    df_train_neg = df_train[df_train['label'] == 0]\n",
    "\n",
    "    # some input validation for train_size\n",
    "    max_train_size = int(df_train_pos.shape[0] / pct_positive)\n",
    "    if not train_size:\n",
    "        train_size = max_train_size\n",
    "    elif train_size > max_train_size:\n",
    "        warnings.warn(f'train_size of {train_size} exceeds the amount of '\n",
    "        'training data available for the given parameters. '\n",
    "        f'Resetting train size to {max_train_size}')\n",
    "        train_size = max_train_size\n",
    "    else:\n",
    "        train_size = int(train_size)\n",
    "\n",
    "    # assemble train dataframe\n",
    "    num_pos_samples = int(pct_positive * train_size)\n",
    "    num_neg_samples = train_size - num_pos_samples\n",
    "\n",
    "    df_train = pd.concat([\n",
    "        df_train_pos.sample(num_pos_samples, random_state=random_state),\n",
    "        df_train_neg.sample(num_neg_samples)]).sample(\n",
    "        frac=1, random_state=random_state)\n",
    "\n",
    "    X_train = df_train['comment']\n",
    "    y_train = df_train['label']\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d8fe17-d5a1-4106-9554-6b1b5c62e273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create custom train/test split using function Christian created to create equal classes\n",
    "\n",
    "X_train, X_test, y_train, y_test = split_data(data = aggression, pct_positive = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8f874e6f-93a3-493d-8943-fc4f231b911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe to store model results\n",
    "\n",
    "column_names = ['model', 'file', 'cv__stop_words', 'cv__max_df', 'cv__max_features', 'cv__min_df', 'training_score', 'test_score']\n",
    "\n",
    "model_df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "# Create function to add results to model df\n",
    "\n",
    "def add_to_model(df, model, name, file):\n",
    "    df = df.append({'model'           : name,\n",
    "                    'file'            : file,\n",
    "                    'cv__stop_words'  : model.best_params_['cv__stop_words'],\n",
    "                    'cv__max_df'      : model.best_params_['cv__max_df'],\n",
    "                    'cv__max_features': model.best_params_['cv__max_features'],\n",
    "                    'cv__min_df'      : model.best_params_['cv__min_df'],\n",
    "                    'cv__ngram_range' : model.best_params_['cv__ngram_range'],\n",
    "                    'training_score'  : model.score(X_train, y_train),\n",
    "                    'test_score'      : model.score(X_test, y_test)},\n",
    "                    ignore_index = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "130f505a-f4cc-4a5d-b438-608580a22fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to count vectorize and run logistic regression\n",
    "\n",
    "pipe = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegression(max_iter = 1_000))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1985eec0-908a-4c68-9f7e-b72d104a616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters for pipeline\n",
    "\n",
    "pipe_params = {\n",
    "    'cv__stop_words'  : [None, 'english'],\n",
    "    'cv__max_features': [12_000, 15_000],\n",
    "    'cv__min_df'      : [2, 3],\n",
    "    'cv__max_df'      : [.85, .9],\n",
    "    'cv__ngram_range' : [(1, 1), (2, 2)]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2aa82881-59d9-4f8b-878e-d0a6daa3ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate gridsearch\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator  = pipe,\n",
    "    param_grid = pipe_params,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad0c5285-6e6d-48d3-a855-571fca43d490",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegression(max_iter=1000))]),\n",
       "             param_grid={'cv__max_df': [0.85, 0.9],\n",
       "                         'cv__max_features': [12000, 15000],\n",
       "                         'cv__min_df': [2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cv__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the gridsearch\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5da2fac5-5bb5-45a3-a66d-1f6e4891ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = add_to_model(model_df, gs, 'logistic regression', 'aggression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "479d5221-92d0-4b93-bffa-6558538cdfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>file</th>\n",
       "      <th>cv__stop_words</th>\n",
       "      <th>cv__max_df</th>\n",
       "      <th>cv__max_features</th>\n",
       "      <th>cv__min_df</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>cv__ngram_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.953827</td>\n",
       "      <td>0.869772</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>0.953827</td>\n",
       "      <td>0.869772</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>None</td>\n",
       "      <td>0.85</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>0.959457</td>\n",
       "      <td>0.871129</td>\n",
       "      <td>(1, 1)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model        file cv__stop_words  cv__max_df  \\\n",
       "0  logistic regression  aggression           None        0.90   \n",
       "1  logistic regression  aggression           None        0.90   \n",
       "2  logistic regression  aggression           None        0.85   \n",
       "\n",
       "  cv__max_features cv__min_df  training_score  test_score cv__ngram_range  \n",
       "0            12000          2        0.953827    0.869772          (1, 1)  \n",
       "1            12000          2        0.953827    0.869772          (1, 1)  \n",
       "2            15000          3        0.959457    0.871129          (1, 1)  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "16bead0b-5a2c-4c69-a6d1-02e58ee77efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df = model_df[['model', 'file', 'cv__stop_words', 'cv__max_df', 'cv__max_features', 'cv__min_df', 'cv__ngram_range', 'training_score', 'test_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a655f74-8c9b-4782-85ef-c6d4fef6e365",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df.to_csv('../data/lr_model_results.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "ffa9d940-9f27-4c99-87cf-2f37a38a9ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.read_csv('../data/lr_model_results.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3612f9f3-7995-403e-b746-1bf48fce7799",
   "metadata": {},
   "source": [
    "#### Results of gridsearch on the different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6f063bdb-5c0f-4497-b0bc-e902cc65fec1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>file</th>\n",
       "      <th>cv__stop_words</th>\n",
       "      <th>cv__max_df</th>\n",
       "      <th>cv__max_features</th>\n",
       "      <th>cv__min_df</th>\n",
       "      <th>cv__ngram_range</th>\n",
       "      <th>training_score</th>\n",
       "      <th>test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.953827</td>\n",
       "      <td>0.869772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.953827</td>\n",
       "      <td>0.869772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>aggression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>15000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.959457</td>\n",
       "      <td>0.871129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>toxic</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12000</td>\n",
       "      <td>3</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.965972</td>\n",
       "      <td>0.896686</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>attacks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.956063</td>\n",
       "      <td>0.883812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>attacks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.85</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.960635</td>\n",
       "      <td>0.884822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>logistic regression</td>\n",
       "      <td>attacks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.80</td>\n",
       "      <td>12000</td>\n",
       "      <td>2</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>0.960635</td>\n",
       "      <td>0.884822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model        file  cv__stop_words  cv__max_df  \\\n",
       "0  logistic regression  aggression             NaN        0.90   \n",
       "1  logistic regression  aggression             NaN        0.90   \n",
       "2  logistic regression  aggression             NaN        0.85   \n",
       "3  logistic regression       toxic             NaN        0.90   \n",
       "4  logistic regression       toxic             NaN        0.85   \n",
       "5  logistic regression       toxic             NaN        0.85   \n",
       "6  logistic regression     attacks             NaN        0.90   \n",
       "7  logistic regression     attacks             NaN        0.85   \n",
       "8  logistic regression     attacks             NaN        0.80   \n",
       "\n",
       "   cv__max_features  cv__min_df cv__ngram_range  training_score  test_score  \n",
       "0             12000           2          (1, 1)        0.953827    0.869772  \n",
       "1             12000           2          (1, 1)        0.953827    0.869772  \n",
       "2             15000           3          (1, 1)        0.959457    0.871129  \n",
       "3             12000           3          (1, 1)        0.965972    0.896686  \n",
       "4             12000           3          (1, 1)        0.965972    0.896686  \n",
       "5             12000           3          (1, 1)        0.965972    0.896686  \n",
       "6             10000           2          (1, 1)        0.956063    0.883812  \n",
       "7             12000           2          (1, 1)        0.960635    0.884822  \n",
       "8             12000           2          (1, 1)        0.960635    0.884822  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2d1abf-18da-41c2-a9e7-b0cbb34e039d",
   "metadata": {},
   "source": [
    "#### Add in Regularization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b504b12-1b40-4829-8b84-01ae7f4e2fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline to count vectorize and run logistic regression with regularization\n",
    "\n",
    "pipe_reg = Pipeline([\n",
    "    ('cv', CountVectorizer()),\n",
    "    ('lr', LogisticRegressionCV(penalty = 'l1', solver = 'liblinear', max_iter = 1_000))\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40925486-5e70-438a-b8fa-c4de6918d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create parameters for pipeline\n",
    "\n",
    "pipe_params_reg = {\n",
    "    'cv__stop_words'  : [None, 'english'],\n",
    "    'cv__max_features': [12_000, 15_000],\n",
    "    'cv__min_df'      : [2, 3],\n",
    "    'cv__max_df'      : [.85, .9],\n",
    "    'cv__ngram_range' : [(1, 1), (2, 2)],\n",
    "    'lr__Cs'          : [1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c08c89fe-28e6-4f3a-bc9f-98559d327b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate gridsearch\n",
    "\n",
    "gs_reg = GridSearchCV(\n",
    "    estimator  = pipe_reg,\n",
    "    param_grid = pipe_params_reg,\n",
    "    cv = 5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51e28c69-e059-40c6-b47f-5375ee051d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cv', CountVectorizer()),\n",
       "                                       ('lr',\n",
       "                                        LogisticRegressionCV(max_iter=1000,\n",
       "                                                             penalty='l1',\n",
       "                                                             solver='liblinear'))]),\n",
       "             param_grid={'cv__max_df': [0.85, 0.9],\n",
       "                         'cv__max_features': [12000, 15000],\n",
       "                         'cv__min_df': [2, 3],\n",
       "                         'cv__ngram_range': [(1, 1), (2, 2)],\n",
       "                         'cv__stop_words': [None, 'english'], 'lr__Cs': [1]})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the gridsearch\n",
    "\n",
    "gs_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d287abd6-c249-4f94-8c4d-df6be40965ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv__max_df': 0.85,\n",
       " 'cv__max_features': 12000,\n",
       " 'cv__min_df': 2,\n",
       " 'cv__ngram_range': (1, 1),\n",
       " 'cv__stop_words': None,\n",
       " 'lr__Cs': 1}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6319ec0c-378b-4759-a74b-70e02b665a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a5a6023-824c-4d79-b900-620d8b213ccd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8534360839322308"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffa07da9-f3f8-4737-8338-88f90eaf3a76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
